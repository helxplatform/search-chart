fullnameOverride: ""
nameOverride: ""
airflow:
  # -- Enable airflow deployment
  # @section -- Airflow
  enabled: true
  # @ignored
  pgbouncer:
    enabled: false
  airflow:
    # @ignore
    dbMigrations:
      # -- Disables dbMigration, useful if previous deployment is same airflow version.
      # @section -- Airflow
      enabled: true
      ## if a post-install helm Job should be used (instead of a Deployment)
      ## - [WARNING] setting `true` will NOT work with the helm `--wait` flag,
      ##   this is because post-install helm Jobs run AFTER the main resources become Ready,
      ##   which will cause a deadlock, as other resources require db-migrations to become Ready
      ##
      runAsJob: true
    # -- Airflow custom image, that contains dug and other libraries installed.
    # @section -- Airflow
    image:
      repository: containers.renci.org/helxplatform/roger
      tag: "latest"
      pullPolicy: Always
    # -- Airflow config
    # @section -- Airflow
    config:
      AIRFLOW__CORE__LOAD_EXAMPLES: "FALSE"
      AIRFLOW__LOGGING_LEVEL: "INFO"
      AIRFLOW__SCHEDULER__SCHEDULE_AFTER_TASK_EXECUTION: "FALSE"
      AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "TRUE"
      AIRFLOW__WEBSERVER__BASE_URL: ""
    # @ignore
    configSecretsName: airflow-config-secrets
    # @ignore
    executor: KubernetesExecutor
    # -- Environment variables used by roger. For full option please refer to [Roger config.yaml](https://github.com/helxplatform/roger/blob/develop/dags/roger/config/config.yaml)
    # @section -- Airflow
    extraEnv:
      - name: ROGER_LAKEFS__CONFIG_ENABLED
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_enabled
      - name: ROGER_LAKEFS__CONFIG_HOST
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_host
      - name: ROGER_LAKEFS__CONFIG_ACCESS__KEY__ID
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_access_key_id      
      - name: ROGER_LAKEFS__CONFIG_SECRET__ACCESS__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_secret_access_key
      - name: ROGER_LAKEFS__CONFIG_BRANCH
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_branch
      - name: ROGER_LAKEFS__CONFIG_REPO
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: lakefs_repo
      - name: ROGER_ANNOTATION_NORMALIZER
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: normalizer_url
      - name: ROGER_ANNOTATION_ANNOTATOR__TYPE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_type
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_MONARCH_URL
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_monarch_url
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_CLASSIFICATION__URL
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_classification_url
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_ANNOTATOR__URL
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_annotator_url
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_ENABLED
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_enabled
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_URL
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_url
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_PROMPT
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_prompt
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_LLM__MODEL__NAME
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_llm_model_name
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_ORGANIZATION
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_llm_organization
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_ACCESS__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_bagel_llm_access_key
      - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_SCORE__THRESHOLD
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_sapbert_score_threshold
      - name: ROGER_ANNOTATION_SYNONYM__SERVICE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: synonymizer_url
      - name: ROGER_DATA_DIR
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_directory
      - name: ROGER_DUG__INPUTS_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: input_sets
      - name: ROGER_DUG__INPUTS_DATA__SOURCE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_source
      - name: ROGER_ELASTICSEARCH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-elastic-config
            key: host
      - name: ROGER_ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: password      
      - name: ROGER_ELASTICSEARCH_USERNAME
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: username
      - name: ROGER_ELASTICSEARCH_SCHEME
        value: "https"
      - name: ROGER_ELASTICSEARCH_CA__PATH
        value: "/opt/certs/es.crt"          
      - name: ROGER_REDISGRAPH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: host
      - name: ROGER_REDISGRAPH_GRAPH
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: graph
      - name: ROGER_REDISGRAPH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-redis-secret
            key: password
      - name: ROGER_REDISGRAPH_PORT
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: port
      - name: ROGER_S3_ACCESS__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_access_key
      - name: ROGER_S3_BUCKET
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_bucket
      - name: ROGER_S3_HOST
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_host
      - name: ROGER_S3_SECRET__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_secret_key
      - name: ROGER_KGX_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: kgx_data_sets
      - name: ROGER_INDEXING_NODE__TO__ELEMENT__QUERIES_ENABLED
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: node_to_queries_enabled
      - name: ROGER_INDEXING_ELEMENT__MAPPING
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: element_mappings
      - name: ROGER_ELASTICSEARCH_NBOOST__HOST
        value: nboost $ TODO compute this
      - name: ROGER_INDEXING_TRANQL__ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: tranql_endpoint
      - name: AIRFLOW__CORE__FERNET_KEY
        valueFrom:
          secretKeyRef:
            # Same as airflow.configSecretsName
            name: airflow-config-secrets
            key: fernet-key
    # -- These volumes are mounted on all airflow pods , aswell as executor pods.
    # @section -- Airflow
    extraVolumeMounts:
      # --
      - name: airflow-data
        mountPath: /opt/airflow/share/data
      - name: es-cert
        mountPath: "/opt/certs/es.crt"
        subPath: "ca.crt"
    # -- Volumes section for all airflow pods, including executor pods.
    # @section -- Airflow
    extraVolumes:
      - name: airflow-data
        persistentVolumeClaim:
          claimName: search-data
      - name: es-cert
        secret:
          secretName: elasticsearch-master-certs
          defaultMode: 0777
    # -- Executor pod configuration
    # @raw
    # @section -- Airflow
    kubernetesPodTemplate:
      resources:
        limits:
          cpu: 2
          memory: 16G
        requests:
          cpu: 2
          memory: 16G
    # -- Update user table on deployments
    # @section -- Airflow
    usersUpdate: true
  # @yaml
  # -- Defines the location of dags
  # @section -- Airflow
  dags:
    gitSync:
      enabled: true
      repo: "https://github.com/helxplatform/roger.git"
      repoSubPath: "dags"
      branch: "main"
      revision: "HEAD"
      syncWait: 60
  # @ignore
  externalRedis:
    host: ""
    passwordSecret: search-redis-secret
    passwordSecretKey: password
  # @ignore
  flower:
    enabled: false
  # @ignore
  logs:
    path: /opt/airflow/share/logs
    persistence:
      enabled: true
      storageClass: "" ## WARNING: your StorageClass MUST SUPPORT `ReadWriteMany`
      accessMode: ReadWriteMany
      size: 5Gi
  # @ignore
  redis:
    enabled: false
  # @raw
  # -- Airflow scheduler config
  # @section -- Airflow
  scheduler:
    logCleanup:
      enabled: false
    resources:
      limits:
        cpu: 2
        memory: 4G
      requests:
        cpu: 2
        memory: 4G
  # @raw
  # -- Airflow webui config
  # @section -- Airflow
  web:
    resources:
      limits:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G
      requests:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G
  # @ignore
  workers:
    enabled: false
  # @ignore
  triggerer:
    enabled: false

# -- Airflow storage for executors , scheduler and web pods. This is a shared volume.
# @section -- Airflow
persistence:
  storageClass: ""
  pvcSize: 32Gi



api:
  # -- Number of relicas for Dug API server
  # @section -- Dug API Server
  replicas: 4
  # -- Connection Scheme to elastic search
  # @section -- Dug API Server
  elasticScheme: "https"
  # -- Default location to elastic search tls certificate
  # @section -- Dug API Server
  certMountPath: "/usr/lib/ssl/certs/ca_elastic.crt"
  # -- Container image
  # @section -- Dug API Server
  image:
    repository: containers.renci.org/helxplatform/dug
    tag: ""
    pullPolicy: Always
  # @ignore
  appName: webserver
  # @ignore
  debug: false
  # -- Deployment pod Configuration
  # @raw
  # @section -- Dug API Server
  deployment:
    apiPort: 5551
    apiWorkers: 8
    apiTimeout: 10
    extraEnv: []
    logLevel: INFO
    imagePullSecrets: []
    resources:
      limits:
        cpu: 2
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi


  service:
    # -- This should match release name in this example the helm release name was `search`
    # @section -- Dug API Server
    name: search-api
    # -- Search service annotation
    # @section -- Dug API Server
    annotations: {}
    # -- API port on deployment
    # @section -- Dug API Server
    apiPort: "5551"
    # -- Service port
    # @section -- Dug API Server
    port: "5551"
    # -- Service type
    # @section -- Dug API Server
    type: ClusterIP



# @section -- Application Config
config:
  # @TODO find permanent solution for study level data.
  # @ignore
  program_config: {}
  # @ignore
  consent_id_config: {}
  # @ignore
  missing_studies: []
  # @ignore
  missing_programs: []

  annotation:
    # -- Annotator type to use , options are `sapbert` or `monarch`
    # @section -- Application Config
    annotator_type: "sapbert"
    # -- Monarch annotator config
    # @raw
    # @section -- Application Config
    monarch:
      url: "https://api.monarchinitiative.org/api/nlp/annotate/entities?min_length=4&longest_only=false&include_abbreviation=false&include_acronym=false&include_numbers=false&content="
    # -- Sapbert annotator config
    # @raw
    # @section -- Application Config
    sapbert:
      classification_url: "https://med-nemo.apps.renci.org/annotate/"
      annotator_url: "https://sap-qdrant.apps.renci.org/annotate/"
      score_threshold: 0.8
      bagel:
        enabled: false
        url: "https://bagel.apps.renci.org/group_synonyms_openai"
        prompt: "bagel/ask_classes"
        llm_args:
          llm_model_name: "gpt-4o-2024-05-13"
          organization: ""
          access_key: ""
    # -- Node normalization url to use during annotation
    # @section -- Application Config
    normalizer_url: https://nodenormalization-sri.renci.org/get_normalized_nodes?conflate=false&description=true&curie=
    # -- Name resolution url to use to find synonyms
    # @section -- Application Config
    synonymizer_url: https://name-resolution-sri.renci.org/reverse_lookup

  # -- Input dataset to include during ingestion. These refer to repo names on lakefs. With version (branch) tags.
  # @section -- Application Config
  input_sets: "bdc:v2.0,topmed:v2.0"
  # Depricated
  # @ignore
  data_source: "stars"
  # -- Knowledge graph input datasets to ingest for the dug Knowledge graph. These are lakefs repo names with version(branches) as tags.
  # @section -- Application Config
  kgx_data_sets: "baseline-graph:v5.0,cde-graph:v5.0"
  # -- Enables CDE extraction from Knowledge graph.
  # @section -- Application Config
  node_to_queries_enabled: "false"
  # -- colon seperated mappings list by comma, eg : dbgap:Non-HEAL Studies,bacpac:HEAL Research Programs, used to map parser outputs to other values.
  # @section -- Application Config
  element_mappings: ""
  # Deprecated
  # @ignore
  s3:
    host: ""
    bucket: ""
    access_key: ""
    secret_key: ""

  lakefs:
    # -- Enables lakefs usage for input and output on data ingest.
    # @section -- Application Config
    enable: False
    # -- Lakefs host address
    # @section -- Application Config
    host: ""
    # -- Lakefs access key
    # @section -- Application Config
    access_key: ""
    # -- Lakefs secret key
    # @section -- Application Config
    secret_key: ""
    # -- Branch to write output files to.
    # @section -- Application Config
    branch: ""
    # -- Lakefs repo to write outputs to
    # @section -- Application Config
    repo: ""

# --  Elastic search for more information checkout full elasticsearch chart options at [https://github.com/elastic/helm-charts/tree/v8.5.1](https://github.com/elastic/helm-charts/tree/v8.5.1)
# @raw
# @section -- Elasticsearch
elasticsearch:

  enabled: true
  esJavaOpts: "-Xmx6g -Xms6g -Dlog4j2.disable.jmx=true -Dlog4j2.formatMsgNoLookups=true"
  clusterHealthCheckParams: "wait_for_status=green&timeout=1s"
  secret:
    enabled: False
  extraEnvs:
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: password
    - name: ELASTIC_USERNAME
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: username
    - name: LOG4J_FORMAT_MSG_NO_LOOKUPS
      value: "true"
  imageTag: "8.5.2"
  maxUnavailable: 0
  replicas: 3
  resources:
    limits:
      cpu: 1
      memory: 8G
      ephemeral-storage: 256Mi
    requests:
      cpu: 1
      memory: 8G
      ephemeral-storage: 256Mi
  sysctlInitContainer:
    enabled: false
# -- Values to enable ingress
# @raw
# @section -- Ingress
ingress:
  pathType: Prefix
  className: ""
  enabled: false
  basicAuth:
    enabled: false
    username: ""
    password: ""
  annotations:
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"
    nginx.ingress.kubernetes.io/cors-allow-methods: "POST, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "Content-Type"
  hosts:
    - host: chart-example.local
  labels: {}
  paths:
    - path: "/"
      name: ui
      port: 80
      prepend: true
    - path: "/airflow"
      name: web
      port: 8080
      prepend: true
    - path: "/tranql"
      name: tranql
      prepend: true
      port: 8081
  rewrite_paths:
    - path: "/search-api(/|$)(.*)"
      name: api
      port: 5551
      prepend: true
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- Redis (Redis Graph)  for more information checkout full redis  chart options at [https://github.com/bitnami/charts/tree/redis/18.1.1/bitnami/redis](https://github.com/bitnami/charts/tree/redis/18.1.1/bitnami/redis)
# @raw
# @section -- Redis
redis:
  commonConfiguration: |-
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 300 100000
  auth:
    existingSecret: search-redis-secret
    existingSecretPasswordKey: password
  clusterDomain: cluster.local
  enabled: true
  image:
    repository: falkordb/falkordb
    tag: v4.0.10
  usePassword: true
  master:
    persistence:
      size: 50Gi
    resources:
      limits:
        cpu: 2
        memory: 45Gi
      requests:
        cpu: 1
        memory: 45Gi
    command: ""
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # spans 25 mins (150 * 10 secs)
      failureThreshold: 1
    livenessProbe:
      # Liveliness probes can be off, since
      # With big cache data to load or sync , redis is alive but
      # responds with LOADING message. to avoid cyclic restarts
      # keeping this off
      enabled: false
    extraFlags:
      - "--loadmodule"
      - "/FalkorDB/bin/src/falkordb.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
  replica:
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 1
      targetCPU: 100
    persistence:
      size: 50G
    resources:
      limits:
        cpu: 2
        memory: 45Gi
      requests:
        cpu: 1
        memory: 45Gi
    extraFlags:
      - "--loadmodule"
      - "/FalkorDB/bin/src/falkordb.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # Having a lower count will make sure that routing to a replica that
      # is not ready yet to not be routed to.
      failureThreshold: 1
      # make sure its really ready
      successThreshold: 5
    livenessProbe:
      enabled: false

# @ignore
redis-insight:
  # -- Enable/Disable Redis UI
  enabled: false
  # -- Url should be same as public ingress url
  rootUrl: ""


# -- Secrets for passwords
# @section -- Elastic / Redis secrets
secrets:
  elastic:
    name: search-elastic-secret
    user: elastic
    userKey: username
    passwordKey: password
  redis:
    name: search-redis-secret
    passwordKey: password

# -- Tranql API configuration. Please refer to [https://github.com/helxplatform/tranql-chart/tree/main](https://github.com/helxplatform/tranql-chart/tree/main) for more details.
# @raw
# @section -- Tranql
tranql:
  enabled: true
  existingRedis:
    host: ""
    port: 6379
    secret: search-redis-secret
    secretPasswordKey: password
  webPrefix: "/tranql"  # TODO this and the one below should be combined
  extraEnv:
    - name: WEB_PATH_PREFIX
      value: "/tranql"
  gunicorn:
    workerCount: 1
    workerTimeout: 1600
  resources:
    limits:
      cpu: 2
      memory: 2G
    requests:
      cpu: 500m
      memory: 2G
  redis:
    enabled: false

# -- Dug search UI configuration please refer to [https://github.com/helxplatform/ui-chart/tree/master](https://github.com/helxplatform/ui-chart/tree/master) for more options
# @raw
# @section -- Dug (Helx) UI
ui:
  enabled: False
  config:
    brand_name: ""
    brand_description:
      html: "<html></html>"
    analytics:
      enabled: false
    search:
      enabled: "true"
      ## Escaped search endpoint address eg: https:\/\/example.com\/search-api
      url: ""
    tranql_enabled: "true"
    ## Escaped tranql endpoint address eg: https:\/\/example.com\/tranql
    tranql_url: ""
    workspaces:
      # disable workspaces
      enabled: "false"
    hidden_result_tabs: "cdes"
    support:
      help_portal_url: ""
      user_guide_url: ""
      faqs_url: ""
    meta:
      title: "Dug semantic search"
      description: "Dug semantic search"


# -- Configuration option for Dug chatbot UI
# @raw
# @section -- Koios Chat UI
chat:
  enabled: false
  replicas: 1
  root_path: /chat
  image:
    repository: containers.renci.org/helxplatform/dug-chatbot
    tag: v0.0.2
  resources:
    limits:
      cpu: 1
      memory: 1Gi
  config:
    api_url: http://koios-llama-koios-chart.ner/
  apiPort: 8080
  service:
    type: ClusterIP

chat_2:
  enabled: false
  replicas: 1
  root_path: /chat-kg
  image:
    repository: containers.renci.org/helxplatform/dug-chatbot
    tag: v0.0.2
  resources:
    limits:
      cpu: 1
      memory: 1Gi
  config:
    api_url: http://koios-kg-chat-koios-chart.ner/
  apiPort: 8080
  service:
    type: ClusterIP