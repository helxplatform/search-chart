fullnameOverride: ""
nameOverride: ""

# @section -- Airflow
airflow:
  # @section -- Airflow
  defaultAirflowRepository: airflow
  # @section -- Airflow
  airflowVersion: "3.1.1"
  # @section -- Airflow
  images:
    airflow:
      repository: "containers.renci.org/helxplatform/airflow"
      tag: "3.1.1"
  # @section -- Airflow
  data:
    metadataConnection:
      pass: postgres
  # @section -- Airflow
  postgresql:
    auth:
      password: postgres
      postgresPassword: postgres
    image:
      registry: containers.renci.org
      repository: vgl/postgres-alpine
      tag: 18.0.1
  # @section -- Airflow
  extraEnv: |
    - name: ROGER_LAKEFS__CONFIG_ENABLED
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_enabled
    - name: ROGER_LAKEFS__CONFIG_HOST
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_host
    - name: ROGER_LAKEFS__CONFIG_ACCESS__KEY__ID
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_access_key_id
    - name: ROGER_LAKEFS__CONFIG_SECRET__ACCESS__KEY
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_secret_access_key
    - name: ROGER_LAKEFS__CONFIG_BRANCH
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_branch
    - name: ROGER_LAKEFS__CONFIG_REPO
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: lakefs_repo
    - name: ROGER_ANNOTATION_NORMALIZER
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: normalizer_url
    - name: ROGER_ANNOTATION_ANNOTATOR__TYPE
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_type
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_MONARCH_URL
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_monarch_url
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_CLASSIFICATION__URL
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_classification_url
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_ANNOTATOR__URL
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_annotator_url
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_ENABLED
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_enabled
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_URL
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_url
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_PROMPT
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_prompt
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_LLM__MODEL__NAME
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_llm_model_name
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_ORGANIZATION
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_llm_organization
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_BAGEL_LLM__ARGS_ACCESS__KEY
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_bagel_llm_access_key
    - name: ROGER_ANNOTATION_ANNOTATOR__ARGS_SAPBERT_SCORE__THRESHOLD
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: annotator_sapbert_score_threshold
    - name: ROGER_ANNOTATION_SYNONYM__SERVICE
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: synonymizer_url
    - name: ROGER_DATA_DIR
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: data_directory
    - name: ROGER_DUG__INPUTS_DATA__SETS
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: input_sets
    - name: ROGER_ELASTICSEARCH_HOST
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-elastic-config"
          key: host
    - name: ROGER_ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: "{{ .Release.Name }}-elastic-secret"
          key: password
    - name: ROGER_ELASTICSEARCH_USERNAME
      valueFrom:
        secretKeyRef:
          name: "{{ .Release.Name }}-elastic-secret"
          key: username
    - name: ROGER_REDISGRAPH_HOST
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-redis-config"
          key: host
    - name: ROGER_REDISGRAPH_GRAPH
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-redis-config"
          key: graph
    - name: ROGER_REDISGRAPH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: "{{ .Release.Name }}-redis-secret"
          key: password
    - name: ROGER_REDISGRAPH_PORT
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-redis-config"
          key: port
    - name: ROGER_S3_ACCESS__KEY
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: s3_access_key
    - name: ROGER_S3_BUCKET
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: s3_bucket
    - name: ROGER_S3_HOST
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: s3_host
    - name: ROGER_S3_SECRET__KEY
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: s3_secret_key
    - name: ROGER_KGX_DATA__SETS
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: kgx_data_sets
    - name: ROGER_INDEXING_NODE__TO__ELEMENT__QUERIES_ENABLED
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: node_to_queries_enabled
    - name: ROGER_INDEXING_ELEMENT__MAPPING
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: element_mappings
    - name: ROGER_ELASTICSEARCH_NBOOST__HOST
      value: nboost $ TODO compute this
    - name: ROGER_INDEXING_TRANQL__ENDPOINT
      valueFrom:
        configMapKeyRef:
          name: "{{ .Release.Name }}-data-config"
          key: tranql_endpoint
    - name: AIRFLOW__KUBERNETES_EXECUTOR__DELETE_WORKER_PODS
      value: "FALSE"
    - name: "AIRFLOW__LOGGING__LOGGING_LEVEL"
      value: "DEBUG"
    - name: "AIRFLOW__LOGGING__BASE_LOG_FOLDER"
      value: "/opt/airflow/share/logs"
    - name: "AIRFLOW__WEBSERVER__APPLICATION_ROOT"
      value: "/airflow"
    - name: ROGER_ELASTICSEARCH_SCHEME
      value: "https"
    - name: ROGER_ELASTICSEARCH_CA__PATH
      value: "/opt/certs/es.crt"


  # @section -- Airflow
  volumes:
    - name: airflow-data
      persistentVolumeClaim:
        claimName: 'search-data'
    - name: es-cert
      secret:
        secretName: elasticsearch-master-certs
        defaultMode: 0777
    - name: airflow-logs
      persistentVolumeClaim:
        claimName: 'search-airflow-logs'
  # @section -- Airflow
  volumeMounts:
    - name: airflow-data
      mountPath: /opt/airflow/share/data
    - name: airflow-logs
      mountPath: /opt/airflow/share/logs
    - name: es-cert
      mountPath: "/opt/certs/es.crt"
      subPath: "ca.crt"
  # @section -- Airflow
  executor: "KubernetesExecutor"
  # @section -- Airflow
  dagProcessor:
    enabled: true
    logGroomerSidecar:
      enabled: false
    resources:
      limits:
        cpu: 2
        memory: 2Gi
  # @section -- Airflow
  workers:
    replicas: 0
    logGroomerSidecar:
      enabled: false
  # @section -- Airflow
  config:
    api:
      # This is the key for internal API authentication
      auth_backends: airflow.api.auth.backend.basic_auth
    # Ensure these are set
    core:
      internal_api_secret_key: "{{ .Values.webserverSecretKey }}"
  # @section -- Airflow
  webserverSecretKey: "your-secret-key-here"
  # @section -- Airflow
  scheduler:
    env:
      - name: AIRFLOW__CORE__EXECUTOR
        value: "KubernetesExecutor"
    resources:
      limits:
        cpu: 1
        memory: 2Gi
    logGroomerSidecar:
      # Whether to deploy the Airflow scheduler log groomer sidecar.
      enabled: false
    startupProbe:
      command:
        - bash
        - -c
        - |
          airflow jobs check --job-type SchedulerJob --hostname "$(hostname)"
    livenessProbe:
      command:
        - bash
        - -c
        - |
          airflow jobs check --job-type SchedulerJob --hostname "$(hostname)"
  # @section -- Airflow
  apiServer:
    resources:
      limits:
        cpu: 1
        memory: 2Gi
  # @section -- Airflow
  webServer:
    defaultUser:
      enabled: true
      role: Admin
      username: admin
      email: admin@example.com
      firstName: admin
      lastName: user
      password: admin
  # @section -- Airflow
  triggerer:
    enabled: false
  # @section -- Airflow
  statsd:
    enabled: false
  # @section -- Airflow
  redis:
    enabled: false
    serviceAccount:
      create: false
  # @section -- Airflow
  dags:
    persistence:
      # Enable persistent volume for storing dags
      enabled: false
    gitSync:
      enabled: true
      repo: https://github.com/helxplatform/roger.git
      branch: main
      subPath: "dags"          

api:
  # -- Number of relicas for Dug API server
  # @section -- Dug API Server
  replicas: 4
  # -- Connection Scheme to elastic search
  # @section -- Dug API Server
  elasticScheme: "https"
  # -- Default location to elastic search tls certificate
  # @section -- Dug API Server
  certMountPath: "/usr/lib/ssl/certs/ca_elastic.crt"
  # -- Container image
  # @section -- Dug API Server
  image:
    repository: containers.renci.org/helxplatform/dug
    tag: ""
    pullPolicy: Always
  # @ignore
  appName: webserver
  # @ignore
  debug: false
  # -- Deployment pod Configuration
  # @raw
  # @section -- Dug API Server
  deployment:
    apiPort: 5551
    apiWorkers: 8
    apiTimeout: 10
    extraEnv: []
    logLevel: INFO
    imagePullSecrets: []
    resources:
      limits:
        cpu: 2
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi


  service:
    # -- This should match release name in this example the helm release name was `search`
    # @section -- Dug API Server
    name: search-api
    # -- Search service annotation
    # @section -- Dug API Server
    annotations: {}
    # -- API port on deployment
    # @section -- Dug API Server
    apiPort: "5551"
    # -- Service port
    # @section -- Dug API Server
    port: "5551"
    # -- Service type
    # @section -- Dug API Server
    type: ClusterIP



# @section -- Application Config
config:
  # @ignore
  program_study_mappings: []

  annotation:
    # -- Annotator type to use , options are `sapbert` or `monarch`
    # @section -- Application Config
    annotator_type: "sapbert"
    # -- Monarch annotator config
    # @raw
    # @section -- Application Config
    monarch:
      url: "https://api.monarchinitiative.org/api/nlp/annotate/entities?min_length=4&longest_only=false&include_abbreviation=false&include_acronym=false&include_numbers=false&content="
    # -- Sapbert annotator config
    # @raw
    # @section -- Application Config
    sapbert:
      classification_url: "https://med-nemo.apps.renci.org/annotate/"
      annotator_url: "https://sap-qdrant.apps.renci.org/annotate/"
      score_threshold: 0.8
      bagel:
        enabled: false
        url: "https://bagel.apps.renci.org/group_synonyms_openai"
        prompt: "bagel/ask_classes"
        llm_args:
          llm_model_name: "gpt-4o-2024-05-13"
          organization: ""
          access_key: ""
    # -- Node normalization url to use during annotation
    # @section -- Application Config
    normalizer_url: https://nodenormalization-sri.renci.org/get_normalized_nodes?conflate=false&description=true&curie=
    # -- Name resolution url to use to find synonyms
    # @section -- Application Config
    synonymizer_url: https://name-resolution-sri.renci.org/reverse_lookup

  # -- Input dataset to include during ingestion. These refer to repo names on lakefs. With version (branch) tags.
  # @section -- Application Config
  input_sets: "bdc:v2.0,topmed:v2.0"
  # -- Knowledge graph input datasets to ingest for the dug Knowledge graph. These are lakefs repo names with version(branches) as tags.
  # @section -- Application Config
  kgx_data_sets: "baseline-graph:v5.0,cde-graph:v5.0"
  # -- Enables CDE extraction from Knowledge graph.
  # @section -- Application Config
  node_to_queries_enabled: "false"
  # -- colon seperated mappings list by comma, eg : dbgap:Non-HEAL Studies,bacpac:HEAL Research Programs, used to map parser outputs to other values.
  # @section -- Application Config
  element_mappings: ""
  # Deprecated
  # @ignore
  s3:
    host: "http://s3.aws"
    bucket: "bucket"
    access_key: "access-key"
    secret_key: "secret-key"

  lakefs:
    # -- Enables lakefs usage for input and output on data ingest.
    # @section -- Application Config
    enabled: True
    # -- Lakefs host address
    # @section -- Application Config
    host: "https://lakefs.apps.renci.org"
    # -- Lakefs access key
    # @section -- Application Config
    access_key: "accesskey"
    # -- Lakefs secret key
    # @section -- Application Config
    secret_key: "secretkey"
    # -- Branch to write output files to.
    # @section -- Application Config
    branch: "main"
    # -- Lakefs repo to write outputs to
    # @section -- Application Config
    repo: "test-repo"

# --  Elastic search for more information checkout full elasticsearch chart options at [https://github.com/elastic/helm-charts/tree/v8.5.1](https://github.com/elastic/helm-charts/tree/v8.5.1)
# @raw
# @section -- Elasticsearch
elasticsearch:

  enabled: true
  esJavaOpts: "-Xmx6g -Xms6g -Dlog4j2.disable.jmx=true -Dlog4j2.formatMsgNoLookups=true"
  clusterHealthCheckParams: "wait_for_status=green&timeout=1s"
  secret:
    enabled: False
  extraEnvs:
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: password
    - name: ELASTIC_USERNAME
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: username
    - name: LOG4J_FORMAT_MSG_NO_LOOKUPS
      value: "true"
  imageTag: "8.19.6"
  maxUnavailable: 0
  replicas: 3
  resources:
    limits:
      cpu: 1
      memory: 8G
      ephemeral-storage: 256Mi
    requests:
      cpu: 1
      memory: 8G
      ephemeral-storage: 256Mi
  sysctlInitContainer:
    enabled: false
# -- Values to enable ingress
# @raw
# @section -- Ingress
ingress:
  pathType: ImplementationSpecific
  className: ""
  enabled: false
  basicAuth:
    enabled: false
    username: ""
    password: ""
  annotations:
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"
    nginx.ingress.kubernetes.io/cors-allow-methods: "POST, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "Content-Type"
  hosts:
    - host: chart-example.local
  labels: {}
  paths:
    - path: "/"
      name: ui
      port: 80
      prepend: true
    - path: "/tranql"
      name: tranql
      prepend: true
      port: 8081
    - path: "/airflow"
      name: api-server
      port: 8080
      prepend: true
  rewrite_paths:
    - path: "/search-api(/|$)(.*)"
      name: api
      port: 5551
      prepend: true
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- Redis (Redis Graph)  for more information checkout full redis  chart options at [https://github.com/bitnami/charts/tree/redis/18.1.1/bitnami/redis](https://github.com/bitnami/charts/tree/redis/18.1.1/bitnami/redis)
# @raw
# @section -- Redis
redis:
  fullnameOverride: ""
  serviceAccount:
    create: false
  commonConfiguration: |-
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 300 100000
  auth:
    existingSecret: search-redis-secret
    existingSecretPasswordKey: password
  clusterDomain: cluster.local
  enabled: true
  image:
    registry: containers.renci.org
    repository: helxplatform/falkor
    tag: v4.14.4-alpine
  usePassword: true
  master:
    persistence:
      size: 50Gi
    resources:
      limits:
        cpu: 2
        memory: 45Gi
      requests:
        cpu: 1
        memory: 45Gi
    command: ""
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # spans 25 mins (150 * 10 secs)
      failureThreshold: 1
    livenessProbe:
      # Liveliness probes can be off, since
      # With big cache data to load or sync , redis is alive but
      # responds with LOADING message. to avoid cyclic restarts
      # keeping this off
      enabled: false
    extraFlags:
      - "--loadmodule"
      - "/var/lib/falkordb/bin/falkordb.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
  replica:
    replicaCount: 0
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 1
      targetCPU: 100
    persistence:
      size: 50G
    resources:
      limits:
        cpu: 2
        memory: 45Gi
      requests:
        cpu: 1
        memory: 45Gi
    extraFlags:
      - "--loadmodule"
      - "/FalkorDB/bin/src/falkordb.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # Having a lower count will make sure that routing to a replica that
      # is not ready yet to not be routed to.
      failureThreshold: 1
      # make sure its really ready
      successThreshold: 5
    livenessProbe:
      enabled: false

# @ignore
redis-insight:
  # -- Enable/Disable Redis UI
  enabled: false
  # -- Url should be same as public ingress url
  rootUrl: ""


# -- Secrets for passwords
# @section -- Elastic / Redis secrets
secrets:
  elastic:
    name: search-elastic-secret
    user: elastic
    userKey: username
    passwordKey: password
  redis:
    name: search-redis-secret
    passwordKey: password

# -- Tranql API configuration. Please refer to [https://github.com/helxplatform/tranql-chart/tree/main](https://github.com/helxplatform/tranql-chart/tree/main) for more details.
# @raw
# @section -- Tranql
tranql:
  enabled: true
  existingRedis:
    host: ""
    port: 6379
    secret: search-redis-secret
    secretPasswordKey: password
  webPrefix: "/tranql"  # TODO this and the one below should be combined
  extraEnv:
    - name: WEB_PATH_PREFIX
      value: "/tranql"
  gunicorn:
    workerCount: 1
    workerTimeout: 1600
  resources:
    limits:
      cpu: 2
      memory: 2G
    requests:
      cpu: 500m
      memory: 2G
  redis:
    enabled: false

# -- Dug search UI configuration please refer to [https://github.com/helxplatform/ui-chart/tree/master](https://github.com/helxplatform/ui-chart/tree/master) for more options
# @raw
# @section -- Dug (Helx) UI
ui:
  enabled: False
  config:
    brand_name: ""
    brand_description:
      html: "<html></html>"
    analytics:
      enabled: false
    search:
      enabled: "true"
      ## Escaped search endpoint address eg: https:\/\/example.com\/search-api
      url: ""
    tranql_enabled: "true"
    ## Escaped tranql endpoint address eg: https:\/\/example.com\/tranql
    tranql_url: ""
    workspaces:
      # disable workspaces
      enabled: "false"
    hidden_result_tabs: "cdes"
    support:
      help_portal_url: ""
      user_guide_url: ""
      faqs_url: ""
    meta:
      title: "Dug semantic search"
      description: "Dug semantic search"


# -- Configuration option for Dug chatbot UI
# @raw
# @section -- Koios Chat UI
chat:
  enabled: false
  replicas: 1
  root_path: /chat
  image:
    repository: containers.renci.org/helxplatform/koios-ui
    tag: v0.0.1
  config:
    api_url: ##
    public_url: ##
  service:
    type: ClusterIP
  apiPort: 8080
  resources: {}
# -- Configuration option for Dug chatbot UI
# @raw
# @section -- Koios Chat UI
chat_2:
  enabled: false
  replicas: 1
  root_path: /chat-v2
  resources: {}
  image:
    repository: containers.renci.org/helxplatform/koios-ui
    tag: v1.0.0
  config:
    api_url: ##
    public_url: ##
  service:
    type: ClusterIP
  apiPort: 8080


# -- DugLakeFSListener config
duglakefslistener:
  enabled: true
  port: 8001
  git_commit_id: null
  branch: "main"
  airflow_url: "http://airflow:airflow@127.0.0.1:8080/api/v1/"
  service:
    type: ClusterIP
  commands:
    invoke_airflow_with_diff_config:
      {
        "dags": [
          {
            "dag_id": "dag_test",
            "repository_id": "bacpac-test",
            "branch_name": "main",
            "last_commit_id": null
          },
          {
            "dag_id": "annotate_and_index",
            "repository_id": "bacpac",
            "branch_name": "main",
            "last_commit_id": null
          }
        ]
      }
